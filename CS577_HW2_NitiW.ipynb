{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS577 Deep Learning HW2\n",
    "# Niti Wattanasirichaigoon\n",
    "# Implementing Neural Networks without using GPU framework\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes and functions\n",
    "learning_rate = 0.001\n",
    "reg = 1e-3\n",
    "\n",
    "class sigmoidGate():\n",
    "    w = []\n",
    "    x = []\n",
    "    error = []\n",
    "    def __init__(self, weights):\n",
    "        self.w = weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # z = input <dot> weights + bias\n",
    "        w = self.w\n",
    "        z = np.dot(x,w[:-1])+w[-1,]\n",
    "        self.x = x \n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "        \n",
    "    def backward(self,dz):\n",
    "        self.error = np.matmul(np.append(self.x.T,[np.ones(self.x.T.shape[1])],axis=0), dz*(1.0-dz))\n",
    "        return np.matmul(dz*(1.0-dz), self.w[:-1].T)\n",
    "    \n",
    "    \n",
    "class softmaxGate():\n",
    "    w = []\n",
    "    z = []\n",
    "    error = []\n",
    "    def __init__(self, weights):\n",
    "        self.w = weights\n",
    "        \n",
    "    def forward(self, z):\n",
    "        v = self.w\n",
    "        q = np.exp(np.dot(z,v[:-1])+v[-1,])\n",
    "        self.z = z\n",
    "        yhat = (q.T/np.sum(q,axis=1)).T # nx3 matrix\n",
    "        return yhat\n",
    "    \n",
    "    def backward(self,output):\n",
    "        self.error = np.matmul(np.append(self.z.T,[np.ones(self.z.T.shape[1])],axis=0), output)\n",
    "        return np.matmul(output, self.w[:-1].T)\n",
    "    \n",
    "    \n",
    "def crossEntropyLoss(yhat,y):\n",
    "    if y == 1:\n",
    "        return -np.log(yhat)\n",
    "    else:\n",
    "        return -np.log(1-yhat)\n",
    " \n",
    "# class for the Neural Network    \n",
    "class CGraph():\n",
    "    network = []\n",
    "    yhats = []\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        network = []\n",
    "        yhats = []\n",
    "        hidden_layer = sigmoidGate(0.01*np.random.rand(n_inputs+1,n_hidden))\n",
    "        network.append(hidden_layer)\n",
    "        output_layer = softmaxGate(0.01*np.random.rand(n_hidden+1,n_outputs))\n",
    "        network.append(output_layer)\n",
    "        self.network = network\n",
    "        \n",
    "    def forward(self,init_inputs,y):\n",
    "        inputs = init_inputs\n",
    "        for gate in self.network:\n",
    "            new_inputs = gate.forward(inputs)\n",
    "            inputs = new_inputs\n",
    "        yhat = inputs\n",
    "        self.yhats = yhat\n",
    "        # calculate loss and accuracy\n",
    "        success = []\n",
    "        for data in range(y.shape[0]):\n",
    "            if y[data,np.argmax(yhat[data])] == 1:\n",
    "                success.append(1)\n",
    "            else:\n",
    "                success.append(0)\n",
    "            for p in range(y.shape[1]):\n",
    "                inputs[data,p] = crossEntropyLoss(yhat[data,p],y[data,p])\n",
    "            \n",
    "        last_weights = self.network[-1].w\n",
    "        reg_loss = 0.5*reg*np.sum(last_weights*last_weights)\n",
    "        loss = np.sum(inputs)/(y.shape[0]) #+ reg_loss\n",
    "        #print(success)\n",
    "        accuracy = np.mean(success)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def parameterUpdate(self):\n",
    "        for gate in self.network:\n",
    "            gate.w -= learning_rate * (gate.error + reg*gate.w)\n",
    "            \n",
    "    def backward(self,y):\n",
    "        output = self.yhats-y\n",
    "        for gate in self.network[::-1]:\n",
    "            prev_output = gate.backward(output)\n",
    "            output = prev_output\n",
    "        self.parameterUpdate()\n",
    "    \n",
    "    def trainNetwork(self,xTrain,yTrain,num_epochs,batch_size):\n",
    "        loss_hist = []\n",
    "        acc_hist = []\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            loss = []\n",
    "            accuracy = []\n",
    "            for iter in range(xTrain.shape[0]//batch_size-1):\n",
    "                b_loss, b_acc = self.forward(xTrain[iter*batch_size:(iter+1)*batch_size],yTrain[iter*batch_size:(iter+1)*batch_size])\n",
    "                loss.append(b_loss)\n",
    "                accuracy.append(b_acc)\n",
    "                self.backward(yTrain[iter*batch_size:(iter+1)*batch_size])\n",
    "            # remaining unfull batch\n",
    "            b_loss, b_acc = self.forward(xTrain[iter*batch_size:(iter+1)*batch_size],yTrain[iter*batch_size:(iter+1)*batch_size])\n",
    "            loss.append(b_loss)\n",
    "            accuracy.append(b_acc)\n",
    "            self.backward(yTrain[iter*batch_size:(iter+1)*batch_size])\n",
    "            \n",
    "            e_loss = np.mean(loss)\n",
    "            e_acc = np.mean(accuracy)\n",
    "            loss_hist.append(e_loss)\n",
    "            acc_hist.append(e_acc)\n",
    "            print(\"Epoch:\", i+1, \", Loss:\", e_loss, \", Accuracy:\", e_acc)\n",
    "        \n",
    "            \n",
    "    def testNetwork(self,xTest,yTest):\n",
    "        loss, accuracy = self.forward(xTest,yTest)\n",
    "        print(\"Loss:\", loss, \", Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 1.9115289189119273 , Accuracy: 0.25\n",
      "Epoch: 2 , Loss: 1.9107240233251312 , Accuracy: 0.25\n",
      "Epoch: 3 , Loss: 1.9099187657076506 , Accuracy: 0.25\n",
      "Epoch: 4 , Loss: 1.9091131205273952 , Accuracy: 0.25\n",
      "Epoch: 5 , Loss: 1.908307062292761 , Accuracy: 0.25\n",
      "Epoch: 6 , Loss: 1.9075005655504442 , Accuracy: 0.25\n",
      "Epoch: 7 , Loss: 1.9066936048832683 , Accuracy: 0.25\n",
      "Epoch: 8 , Loss: 1.9058861549080284 , Accuracy: 0.25\n",
      "Epoch: 9 , Loss: 1.9050781902733558 , Accuracy: 0.5\n",
      "Epoch: 10 , Loss: 1.904269685657602 , Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Test if NN works\n",
    "computationGraph = CGraph(3,2,3)\n",
    "test = np.array([[1,2,2],[1,2,3],[5,2,3],[3,3,3]])\n",
    "ytest = np.array([[1,0,0],[1,0,0],[1,0,0],[0,1,0]])\n",
    "\n",
    "computationGraph.trainNetwork(test,ytest,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load wine data\n",
    "raw_data = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\")\n",
    "wine_data = np.loadtxt(raw_data, delimiter = \",\")\n",
    "print(wine_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "features = np.array(normalize(wine_data[:,1:], axis=0, norm='max'))\n",
    "label = wine_data[:,0]\n",
    "# change to categorical\n",
    "labels = []\n",
    "for y in label:\n",
    "    row = np.array([0,0,0])\n",
    "    row[int(y)-1] = 1\n",
    "    labels.append(row)\n",
    "labels = np.array(labels)        \n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(features, labels, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 1.908725081358925 , Accuracy: 0.3833333333333333\n",
      "Epoch: 2 , Loss: 1.907780560148276 , Accuracy: 0.3833333333333333\n",
      "Epoch: 3 , Loss: 1.9068661343599531 , Accuracy: 0.3833333333333333\n",
      "Epoch: 4 , Loss: 1.9059705707101842 , Accuracy: 0.3833333333333333\n",
      "Epoch: 5 , Loss: 1.9050849069002245 , Accuracy: 0.3833333333333333\n",
      "Epoch: 6 , Loss: 1.9042026145669952 , Accuracy: 0.3833333333333333\n",
      "Epoch: 7 , Loss: 1.9033200281544407 , Accuracy: 0.3833333333333333\n",
      "Epoch: 8 , Loss: 1.9024370590602684 , Accuracy: 0.3833333333333333\n",
      "Epoch: 9 , Loss: 1.9015581825221228 , Accuracy: 0.3833333333333333\n",
      "Epoch: 10 , Loss: 1.9006936137615025 , Accuracy: 0.3833333333333333\n",
      "Epoch: 11 , Loss: 1.8998604691068117 , Accuracy: 0.3833333333333333\n",
      "Epoch: 12 , Loss: 1.8990835456974384 , Accuracy: 0.3833333333333333\n",
      "Epoch: 13 , Loss: 1.898395201549648 , Accuracy: 0.3833333333333333\n",
      "Epoch: 14 , Loss: 1.8978337880910734 , Accuracy: 0.3833333333333333\n",
      "Epoch: 15 , Loss: 1.8974403266594473 , Accuracy: 0.3833333333333333\n",
      "Epoch: 16 , Loss: 1.8972537061852939 , Accuracy: 0.3833333333333333\n",
      "Epoch: 17 , Loss: 1.8973054608538455 , Accuracy: 0.3833333333333333\n"
     ]
    }
   ],
   "source": [
    "wineNN = CGraph(13,8,3)\n",
    "wineNN.trainNetwork(xTrain,yTrain,17,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8503510315929468 , Accuracy: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "wineNN.testNetwork(xTest,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load seeds data\n",
    "raw_data = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\")\n",
    "seed_data = np.loadtxt(raw_data)\n",
    "print(seed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "features = np.array(normalize(seed_data[:,:7], axis=0, norm='max'))\n",
    "label = seed_data[:,7]\n",
    "# change to categorical\n",
    "labels = []\n",
    "for y in label:\n",
    "    row = np.array([0,0,0])\n",
    "    row[int(y)-1] = 1\n",
    "    labels.append(row)\n",
    "labels = np.array(labels)        \n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(features, labels, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 1.910005249072427 , Accuracy: 0.29375\n",
      "Epoch: 2 , Loss: 1.9099125787244013 , Accuracy: 0.325\n",
      "Epoch: 3 , Loss: 1.9098270530590333 , Accuracy: 0.275\n",
      "Epoch: 4 , Loss: 1.9097475810088083 , Accuracy: 0.3375\n",
      "Epoch: 5 , Loss: 1.909673165989819 , Accuracy: 0.35\n",
      "Epoch: 6 , Loss: 1.9096027820845052 , Accuracy: 0.35\n",
      "Epoch: 7 , Loss: 1.9095353139232754 , Accuracy: 0.35\n",
      "Epoch: 8 , Loss: 1.9094696588149243 , Accuracy: 0.35\n",
      "Epoch: 9 , Loss: 1.909405121011484 , Accuracy: 0.35\n",
      "Epoch: 10 , Loss: 1.9093421360074712 , Accuracy: 0.35\n",
      "Epoch: 11 , Loss: 1.9092830293229535 , Accuracy: 0.35\n",
      "Epoch: 12 , Loss: 1.9092320582497808 , Accuracy: 0.35\n",
      "Epoch: 13 , Loss: 1.9091940488436756 , Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "seedNN = CGraph(7,6,3)\n",
    "seedNN.trainNetwork(xTrain,yTrain,13,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.910160844655512 , Accuracy: 0.30952380952380953\n"
     ]
    }
   ],
   "source": [
    "seedNN.testNetwork(xTest,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 54, 57])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(yTrain,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [1,2,3,4,5,6]\n",
    "np.mean(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3873239436619718"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55/(45+42+55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92312879, 0.56206897, 0.78637771, 0.66666667, 0.66049383,\n",
       "        0.47164948, 0.11023622, 0.75757576, 0.22346369, 0.45230769,\n",
       "        0.56140351, 0.455     , 0.4047619 ],\n",
       "       [0.85569791, 0.2637931 , 0.6996904 , 0.69      , 0.49382716,\n",
       "        0.3556701 , 0.28740157, 0.87878788, 0.45251397, 0.23461538,\n",
       "        0.56140351, 0.515     , 0.29464286],\n",
       "       [0.78354686, 0.34310345, 0.70588235, 0.6       , 0.60493827,\n",
       "        0.77835052, 0.44488189, 0.25757576, 0.37709497, 0.25      ,\n",
       "        0.67836257, 0.74      , 0.20535714],\n",
       "       [0.90357384, 0.67413793, 0.76780186, 0.76666667, 0.62962963,\n",
       "        0.46391753, 0.1476378 , 0.65151515, 0.39385475, 0.56153846,\n",
       "        0.40935673, 0.39      , 0.44642857],\n",
       "       [0.91031693, 0.31206897, 0.80804954, 0.66666667, 0.59259259,\n",
       "        0.65206186, 0.51377953, 0.42424242, 0.46368715, 0.27076923,\n",
       "        0.65497076, 0.955     , 0.50297619],\n",
       "       [0.92582603, 0.25862069, 0.83591331, 0.75      , 0.62345679,\n",
       "        0.77319588, 0.63976378, 0.43939394, 0.66480447, 0.43846154,\n",
       "        0.69590643, 0.6775    , 0.76488095],\n",
       "       [0.82872556, 0.48793103, 0.6873065 , 0.6       , 0.54320988,\n",
       "        0.6314433 , 0.44291339, 0.37878788, 0.55586592, 0.16538462,\n",
       "        0.67251462, 0.825     , 0.17261905],\n",
       "       [0.84962913, 0.23103448, 0.58823529, 0.61666667, 0.54320988,\n",
       "        0.37371134, 0.26771654, 0.43939394, 0.37709497, 0.18846154,\n",
       "        0.60818713, 0.6925    , 0.33452381],\n",
       "       [0.76938638, 0.12758621, 0.77399381, 0.7       , 0.54320988,\n",
       "        0.63917526, 0.39566929, 0.63636364, 0.40223464, 0.23692308,\n",
       "        0.64327485, 0.5775    , 0.25833333],\n",
       "       [0.91975725, 0.53448276, 0.79256966, 0.50666667, 0.71604938,\n",
       "        0.69587629, 0.59645669, 0.25757576, 0.46368715, 0.39230769,\n",
       "        0.56140351, 0.84      , 0.50297619]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
